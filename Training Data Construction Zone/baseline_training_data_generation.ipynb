{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cefc238-8601-4418-a77c-10c2b7c198a3",
   "metadata": {},
   "source": [
    "## Baseline Training Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b34d9-5e21-43f9-a9fc-487aff5fffe1",
   "metadata": {},
   "source": [
    "Here, we perform a similarity search on the texts_images collection to identify image–text pairs, which serve as the baseline training dataset for subsequent fine-tuning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81cc0dc-4227-44a0-81f1-5944c47ca52d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T21:22:10.758994Z",
     "start_time": "2025-10-27T21:22:10.754679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1919, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Temp\\ipykernel_16248\\4262632608.py\", line 6, in <module>\n",
      "    import open_clip\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\open_clip\\__init__.py\", line 3, in <module>\n",
      "    from .coca_model import CoCa\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\open_clip\\coca_model.py\", line 15, in <module>\n",
      "    from .model import CLIPTextCfg, CLIPVisionCfg, _build_vision_tower, _build_text_tower\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\open_clip\\model.py\", line 18, in <module>\n",
      "    from .hf_model import HFTextEncoder\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\open_clip\\hf_model.py\", line 13, in <module>\n",
      "    from transformers import AutoModel, AutoTokenizer, AutoConfig, PretrainedConfig\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 2317, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 2345, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py\", line 23, in <module>\n",
      "    from .auto_factory import (\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 43, in <module>\n",
      "    from ...generation import GenerationMixin\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 2317, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 2345, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py\", line 55, in <module>\n",
      "    from .candidate_generator import (\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\candidate_generator.py\", line 29, in <module>\n",
      "    from sklearn.metrics import roc_curve\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 52, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\SakuraSnow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "# Importing useful dependencies\n",
    "import io\n",
    "import torch\n",
    "import boto3\n",
    "import chromadb\n",
    "import open_clip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "SEED = 10721\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ec9dbb-daf0-4ad0-a635-d418fbe390c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T21:22:09.711655Z",
     "start_time": "2025-10-27T21:22:09.695004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup S3 client for MinIO (MinIO implements Amazon S3 API)\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://127.0.0.1:9000\", # MinIO API endpoint\n",
    "    aws_access_key_id=\"minioadmin\", # User name\n",
    "    aws_secret_access_key=\"minioadmin\", # Password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b94b12-3dde-4ab1-bd66-364e4bfeef55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T21:22:53.421060Z",
     "start_time": "2025-10-27T21:22:52.802581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to the server (Docker Container)\n",
    "client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "\n",
    "# Create or get the collection named \"texts_images\" to store embeddings of images and texts\n",
    "collection_texts_images = client.create_collection(name=\"texts_images\", get_or_create=True, embedding_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6530a273-faa1-4600-94d3-f0e6f2fd172e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'training-data-construction-zone' already exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '1877A5207DB01D9E',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-checksum-crc32': 'AAAAAA==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '1877A5207DB01D9E',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '2107',\n",
       "   'x-ratelimit-remaining': '2107',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Thu, 13 Nov 2025 18:42:18 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       " 'ChecksumCRC32': 'AAAAAA==',\n",
       " 'ChecksumType': 'FULL_OBJECT'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a new Bucket in Min-IO to store our training data\n",
    "\n",
    "# List existing buckets\n",
    "buckets = [b[\"Name\"] for b in s3.list_buckets()[\"Buckets\"]]\n",
    "\n",
    "# Function that given a name, creates a bucket\n",
    "def createBucket(name, list_buckets):\n",
    "    if name in list_buckets:\n",
    "        print(f\"Bucket '{name}' already exists!\")\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=name)\n",
    "        print(f\"Created bucket: {name}\")\n",
    "\n",
    "# Create a bucket named landing_zone\n",
    "createBucket(\"training-data-construction-zone\", buckets)\n",
    "# Sub-bucket: Baseline Training Data\n",
    "s3.put_object(Bucket=\"training-data-construction-zone\", Key=\"baseline-training-data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb0a71f-ce37-46a4-a82a-e4561e96e452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-23): 24 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 768)\n",
       "  (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just in case our device has gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load model\n",
    "model, _, _ = open_clip.create_model_and_transforms(\"hf-hub:laion/CLIP-ViT-L-14-laion2B-s32B-b82K\")\n",
    "tokenizer = open_clip.get_tokenizer(\"hf-hub:laion/CLIP-ViT-L-14-laion2B-s32B-b82K\") # Tokenizer for texts\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ec0fb2f-fc84-4300-910d-8ea911ed1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "# We can use this function to retrieve an text from our bucket\n",
    "def get_text(bucket, key):\n",
    "    resp = s3.get_object(Bucket=bucket, Key=key)\n",
    "    body = resp[\"Body\"].read()\n",
    "    text = body.decode(\"utf-8\")\n",
    "    return text\n",
    "@torch.no_grad()\n",
    "# The next function returns the embedding of the given text\n",
    "def embed_text(model, tokenizer, texts: str):\n",
    "    tokens = tokenizer([texts]).to(device) # tokenized batch\n",
    "    feats = model.encode_text(tokens)\n",
    "    feats = feats / feats.norm(dim=-1, keepdim=True) # normalize\n",
    "    return feats.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "313a798d-b5cb-4764-b141-647bf5ba6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs a similarity search for each text description in the dataset \n",
    "# to retrieve the most similar image, forming image–text pairs for training.\n",
    "def baseline_training_data_generator(src_bucket, dest_bucket, collection, model_text, tokenizer, src_prefix=\"texts/\", dest_prefix=\"baseline-training-data/\"):\n",
    "\n",
    "    # Incremental id assigned to each image-text pair\n",
    "    id_counter = 0\n",
    "\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\") # It returns objects in pages and not all at once.\n",
    "    for page in paginator.paginate(Bucket=src_bucket, Prefix=src_prefix):\n",
    "\n",
    "        # List of paths (meta_data)\n",
    "        image_paths = []\n",
    "        # List of embeddings\n",
    "        embeddings = []\n",
    "        # List of unique IDs for each embedding\n",
    "        ids = []\n",
    "\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "\n",
    "            key = obj[\"Key\"]\n",
    "\n",
    "            if obj['Size'] == 0 and key.endswith(\"/\"): # skip the folder itself\n",
    "                continue\n",
    "\n",
    "            id_counter += 1\n",
    "\n",
    "            # Get the description\n",
    "            description = get_text(src_bucket, key)\n",
    "            # Get the embeddings of the description\n",
    "            q_vec = embed_text(model_text, tokenizer, description)\n",
    "            # Apply the similarity search using the description\n",
    "            res_image = collection.query(\n",
    "                query_embeddings=[q_vec],\n",
    "                n_results=1,\n",
    "                where={\"type\": \"image\"}, # Filter by metadata type\n",
    "                include=[\"documents\", \"distances\"]\n",
    "            )\n",
    "            # Get the key for the image\n",
    "            key_image = res_image['documents'][0][0][len(src_bucket) + 1:]\n",
    "\n",
    "            # Remove the prefix part from the key\n",
    "            new_key_text = dest_prefix + \"text_\" + str(id_counter).zfill(6) + \".txt\" # ids of 000001, 000002, ...\n",
    "            new_key_image = dest_prefix + \"image_\" + str(id_counter).zfill(6) + \".png\" # ids of 000001, 000002, ...\n",
    "\n",
    "            # Copy objects without top-level folder and rename them\n",
    "            copy_source_text = {\"Bucket\": src_bucket, \"Key\": key}\n",
    "            copy_source_image = {\"Bucket\": src_bucket, \"Key\": key_image}\n",
    "            s3.copy_object(Bucket=dest_bucket, Key=new_key_text, CopySource=copy_source_text)\n",
    "            s3.copy_object(Bucket=dest_bucket, Key=new_key_image, CopySource=copy_source_image)\n",
    "\n",
    "            print(f\"✅ Baseline training pair #{id_counter} created successfully.\")\n",
    "\n",
    "    print(f\"✅ All training pairs have been successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c5f64c6-f13a-42eb-b58e-9f7e6cf9c2ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline training pair #1 created successfully.\n",
      "✅ Baseline training pair #2 created successfully.\n",
      "✅ Baseline training pair #3 created successfully.\n",
      "✅ Baseline training pair #4 created successfully.\n",
      "✅ Baseline training pair #5 created successfully.\n",
      "✅ Baseline training pair #6 created successfully.\n",
      "✅ Baseline training pair #7 created successfully.\n",
      "✅ Baseline training pair #8 created successfully.\n",
      "✅ Baseline training pair #9 created successfully.\n",
      "✅ Baseline training pair #10 created successfully.\n",
      "✅ Baseline training pair #11 created successfully.\n",
      "✅ Baseline training pair #12 created successfully.\n",
      "✅ Baseline training pair #13 created successfully.\n",
      "✅ Baseline training pair #14 created successfully.\n",
      "✅ Baseline training pair #15 created successfully.\n",
      "✅ Baseline training pair #16 created successfully.\n",
      "✅ Baseline training pair #17 created successfully.\n",
      "✅ Baseline training pair #18 created successfully.\n",
      "✅ Baseline training pair #19 created successfully.\n",
      "✅ Baseline training pair #20 created successfully.\n",
      "✅ Baseline training pair #21 created successfully.\n",
      "✅ Baseline training pair #22 created successfully.\n",
      "✅ Baseline training pair #23 created successfully.\n",
      "✅ Baseline training pair #24 created successfully.\n",
      "✅ Baseline training pair #25 created successfully.\n",
      "✅ Baseline training pair #26 created successfully.\n",
      "✅ Baseline training pair #27 created successfully.\n",
      "✅ Baseline training pair #28 created successfully.\n",
      "✅ Baseline training pair #29 created successfully.\n",
      "✅ Baseline training pair #30 created successfully.\n",
      "✅ Baseline training pair #31 created successfully.\n",
      "✅ Baseline training pair #32 created successfully.\n",
      "✅ Baseline training pair #33 created successfully.\n",
      "✅ Baseline training pair #34 created successfully.\n",
      "✅ Baseline training pair #35 created successfully.\n",
      "✅ Baseline training pair #36 created successfully.\n",
      "✅ Baseline training pair #37 created successfully.\n",
      "✅ Baseline training pair #38 created successfully.\n",
      "✅ Baseline training pair #39 created successfully.\n",
      "✅ Baseline training pair #40 created successfully.\n",
      "✅ Baseline training pair #41 created successfully.\n",
      "✅ Baseline training pair #42 created successfully.\n",
      "✅ Baseline training pair #43 created successfully.\n",
      "✅ Baseline training pair #44 created successfully.\n",
      "✅ Baseline training pair #45 created successfully.\n",
      "✅ Baseline training pair #46 created successfully.\n",
      "✅ Baseline training pair #47 created successfully.\n",
      "✅ Baseline training pair #48 created successfully.\n",
      "✅ Baseline training pair #49 created successfully.\n",
      "✅ Baseline training pair #50 created successfully.\n",
      "✅ Baseline training pair #51 created successfully.\n",
      "✅ Baseline training pair #52 created successfully.\n",
      "✅ Baseline training pair #53 created successfully.\n",
      "✅ Baseline training pair #54 created successfully.\n",
      "✅ Baseline training pair #55 created successfully.\n",
      "✅ Baseline training pair #56 created successfully.\n",
      "✅ Baseline training pair #57 created successfully.\n",
      "✅ Baseline training pair #58 created successfully.\n",
      "✅ Baseline training pair #59 created successfully.\n",
      "✅ Baseline training pair #60 created successfully.\n",
      "✅ Baseline training pair #61 created successfully.\n",
      "✅ Baseline training pair #62 created successfully.\n",
      "✅ Baseline training pair #63 created successfully.\n",
      "✅ Baseline training pair #64 created successfully.\n",
      "✅ Baseline training pair #65 created successfully.\n",
      "✅ Baseline training pair #66 created successfully.\n",
      "✅ Baseline training pair #67 created successfully.\n",
      "✅ Baseline training pair #68 created successfully.\n",
      "✅ Baseline training pair #69 created successfully.\n",
      "✅ Baseline training pair #70 created successfully.\n",
      "✅ Baseline training pair #71 created successfully.\n",
      "✅ Baseline training pair #72 created successfully.\n",
      "✅ Baseline training pair #73 created successfully.\n",
      "✅ Baseline training pair #74 created successfully.\n",
      "✅ Baseline training pair #75 created successfully.\n",
      "✅ Baseline training pair #76 created successfully.\n",
      "✅ Baseline training pair #77 created successfully.\n",
      "✅ Baseline training pair #78 created successfully.\n",
      "✅ Baseline training pair #79 created successfully.\n",
      "✅ Baseline training pair #80 created successfully.\n",
      "✅ Baseline training pair #81 created successfully.\n",
      "✅ Baseline training pair #82 created successfully.\n",
      "✅ Baseline training pair #83 created successfully.\n",
      "✅ Baseline training pair #84 created successfully.\n",
      "✅ Baseline training pair #85 created successfully.\n",
      "✅ Baseline training pair #86 created successfully.\n",
      "✅ Baseline training pair #87 created successfully.\n",
      "✅ Baseline training pair #88 created successfully.\n",
      "✅ Baseline training pair #89 created successfully.\n",
      "✅ Baseline training pair #90 created successfully.\n",
      "✅ Baseline training pair #91 created successfully.\n",
      "✅ Baseline training pair #92 created successfully.\n",
      "✅ Baseline training pair #93 created successfully.\n",
      "✅ Baseline training pair #94 created successfully.\n",
      "✅ Baseline training pair #95 created successfully.\n",
      "✅ Baseline training pair #96 created successfully.\n",
      "✅ Baseline training pair #97 created successfully.\n",
      "✅ Baseline training pair #98 created successfully.\n",
      "✅ Baseline training pair #99 created successfully.\n",
      "✅ Baseline training pair #100 created successfully.\n",
      "✅ Baseline training pair #101 created successfully.\n",
      "✅ Baseline training pair #102 created successfully.\n",
      "✅ Baseline training pair #103 created successfully.\n",
      "✅ Baseline training pair #104 created successfully.\n",
      "✅ Baseline training pair #105 created successfully.\n",
      "✅ Baseline training pair #106 created successfully.\n",
      "✅ Baseline training pair #107 created successfully.\n",
      "✅ Baseline training pair #108 created successfully.\n",
      "✅ Baseline training pair #109 created successfully.\n",
      "✅ Baseline training pair #110 created successfully.\n",
      "✅ Baseline training pair #111 created successfully.\n",
      "✅ Baseline training pair #112 created successfully.\n",
      "✅ Baseline training pair #113 created successfully.\n",
      "✅ Baseline training pair #114 created successfully.\n",
      "✅ Baseline training pair #115 created successfully.\n",
      "✅ Baseline training pair #116 created successfully.\n",
      "✅ Baseline training pair #117 created successfully.\n",
      "✅ Baseline training pair #118 created successfully.\n",
      "✅ Baseline training pair #119 created successfully.\n",
      "✅ Baseline training pair #120 created successfully.\n",
      "✅ Baseline training pair #121 created successfully.\n",
      "✅ Baseline training pair #122 created successfully.\n",
      "✅ Baseline training pair #123 created successfully.\n",
      "✅ Baseline training pair #124 created successfully.\n",
      "✅ Baseline training pair #125 created successfully.\n",
      "✅ Baseline training pair #126 created successfully.\n",
      "✅ Baseline training pair #127 created successfully.\n",
      "✅ Baseline training pair #128 created successfully.\n",
      "✅ Baseline training pair #129 created successfully.\n",
      "✅ Baseline training pair #130 created successfully.\n",
      "✅ Baseline training pair #131 created successfully.\n",
      "✅ Baseline training pair #132 created successfully.\n",
      "✅ Baseline training pair #133 created successfully.\n",
      "✅ Baseline training pair #134 created successfully.\n",
      "✅ Baseline training pair #135 created successfully.\n",
      "✅ Baseline training pair #136 created successfully.\n",
      "✅ Baseline training pair #137 created successfully.\n",
      "✅ Baseline training pair #138 created successfully.\n",
      "✅ Baseline training pair #139 created successfully.\n",
      "✅ Baseline training pair #140 created successfully.\n",
      "✅ Baseline training pair #141 created successfully.\n",
      "✅ Baseline training pair #142 created successfully.\n",
      "✅ Baseline training pair #143 created successfully.\n",
      "✅ Baseline training pair #144 created successfully.\n",
      "✅ Baseline training pair #145 created successfully.\n",
      "✅ Baseline training pair #146 created successfully.\n",
      "✅ Baseline training pair #147 created successfully.\n",
      "✅ Baseline training pair #148 created successfully.\n",
      "✅ Baseline training pair #149 created successfully.\n",
      "✅ Baseline training pair #150 created successfully.\n",
      "✅ Baseline training pair #151 created successfully.\n",
      "✅ Baseline training pair #152 created successfully.\n",
      "✅ Baseline training pair #153 created successfully.\n",
      "✅ Baseline training pair #154 created successfully.\n",
      "✅ Baseline training pair #155 created successfully.\n",
      "✅ Baseline training pair #156 created successfully.\n",
      "✅ Baseline training pair #157 created successfully.\n",
      "✅ Baseline training pair #158 created successfully.\n",
      "✅ Baseline training pair #159 created successfully.\n",
      "✅ Baseline training pair #160 created successfully.\n",
      "✅ Baseline training pair #161 created successfully.\n",
      "✅ Baseline training pair #162 created successfully.\n",
      "✅ Baseline training pair #163 created successfully.\n",
      "✅ Baseline training pair #164 created successfully.\n",
      "✅ Baseline training pair #165 created successfully.\n",
      "✅ Baseline training pair #166 created successfully.\n",
      "✅ Baseline training pair #167 created successfully.\n",
      "✅ Baseline training pair #168 created successfully.\n",
      "✅ Baseline training pair #169 created successfully.\n",
      "✅ Baseline training pair #170 created successfully.\n",
      "✅ Baseline training pair #171 created successfully.\n",
      "✅ Baseline training pair #172 created successfully.\n",
      "✅ Baseline training pair #173 created successfully.\n",
      "✅ Baseline training pair #174 created successfully.\n",
      "✅ Baseline training pair #175 created successfully.\n",
      "✅ Baseline training pair #176 created successfully.\n",
      "✅ Baseline training pair #177 created successfully.\n",
      "✅ Baseline training pair #178 created successfully.\n",
      "✅ Baseline training pair #179 created successfully.\n",
      "✅ Baseline training pair #180 created successfully.\n",
      "✅ Baseline training pair #181 created successfully.\n",
      "✅ Baseline training pair #182 created successfully.\n",
      "✅ Baseline training pair #183 created successfully.\n",
      "✅ Baseline training pair #184 created successfully.\n",
      "✅ Baseline training pair #185 created successfully.\n",
      "✅ Baseline training pair #186 created successfully.\n",
      "✅ Baseline training pair #187 created successfully.\n",
      "✅ Baseline training pair #188 created successfully.\n",
      "✅ Baseline training pair #189 created successfully.\n",
      "✅ Baseline training pair #190 created successfully.\n",
      "✅ Baseline training pair #191 created successfully.\n",
      "✅ Baseline training pair #192 created successfully.\n",
      "✅ Baseline training pair #193 created successfully.\n",
      "✅ Baseline training pair #194 created successfully.\n",
      "✅ Baseline training pair #195 created successfully.\n",
      "✅ Baseline training pair #196 created successfully.\n",
      "✅ Baseline training pair #197 created successfully.\n",
      "✅ Baseline training pair #198 created successfully.\n",
      "✅ Baseline training pair #199 created successfully.\n",
      "✅ Baseline training pair #200 created successfully.\n",
      "✅ Baseline training pair #201 created successfully.\n",
      "✅ Baseline training pair #202 created successfully.\n",
      "✅ Baseline training pair #203 created successfully.\n",
      "✅ Baseline training pair #204 created successfully.\n",
      "✅ Baseline training pair #205 created successfully.\n",
      "✅ Baseline training pair #206 created successfully.\n",
      "✅ Baseline training pair #207 created successfully.\n",
      "✅ Baseline training pair #208 created successfully.\n",
      "✅ Baseline training pair #209 created successfully.\n",
      "✅ Baseline training pair #210 created successfully.\n",
      "✅ Baseline training pair #211 created successfully.\n",
      "✅ Baseline training pair #212 created successfully.\n",
      "✅ Baseline training pair #213 created successfully.\n",
      "✅ Baseline training pair #214 created successfully.\n",
      "✅ Baseline training pair #215 created successfully.\n",
      "✅ Baseline training pair #216 created successfully.\n",
      "✅ Baseline training pair #217 created successfully.\n",
      "✅ Baseline training pair #218 created successfully.\n",
      "✅ Baseline training pair #219 created successfully.\n",
      "✅ Baseline training pair #220 created successfully.\n",
      "✅ Baseline training pair #221 created successfully.\n",
      "✅ Baseline training pair #222 created successfully.\n",
      "✅ Baseline training pair #223 created successfully.\n",
      "✅ Baseline training pair #224 created successfully.\n",
      "✅ Baseline training pair #225 created successfully.\n",
      "✅ Baseline training pair #226 created successfully.\n",
      "✅ Baseline training pair #227 created successfully.\n",
      "✅ Baseline training pair #228 created successfully.\n",
      "✅ Baseline training pair #229 created successfully.\n",
      "✅ Baseline training pair #230 created successfully.\n",
      "✅ Baseline training pair #231 created successfully.\n",
      "✅ Baseline training pair #232 created successfully.\n",
      "✅ Baseline training pair #233 created successfully.\n",
      "✅ Baseline training pair #234 created successfully.\n",
      "✅ Baseline training pair #235 created successfully.\n",
      "✅ Baseline training pair #236 created successfully.\n",
      "✅ Baseline training pair #237 created successfully.\n",
      "✅ Baseline training pair #238 created successfully.\n",
      "✅ Baseline training pair #239 created successfully.\n",
      "✅ Baseline training pair #240 created successfully.\n",
      "✅ Baseline training pair #241 created successfully.\n",
      "✅ Baseline training pair #242 created successfully.\n",
      "✅ Baseline training pair #243 created successfully.\n",
      "✅ Baseline training pair #244 created successfully.\n",
      "✅ Baseline training pair #245 created successfully.\n",
      "✅ Baseline training pair #246 created successfully.\n",
      "✅ Baseline training pair #247 created successfully.\n",
      "✅ Baseline training pair #248 created successfully.\n",
      "✅ Baseline training pair #249 created successfully.\n",
      "✅ Baseline training pair #250 created successfully.\n",
      "✅ Baseline training pair #251 created successfully.\n",
      "✅ Baseline training pair #252 created successfully.\n",
      "✅ Baseline training pair #253 created successfully.\n",
      "✅ Baseline training pair #254 created successfully.\n",
      "✅ Baseline training pair #255 created successfully.\n",
      "✅ Baseline training pair #256 created successfully.\n",
      "✅ Baseline training pair #257 created successfully.\n",
      "✅ Baseline training pair #258 created successfully.\n",
      "✅ Baseline training pair #259 created successfully.\n",
      "✅ Baseline training pair #260 created successfully.\n",
      "✅ Baseline training pair #261 created successfully.\n",
      "✅ Baseline training pair #262 created successfully.\n",
      "✅ Baseline training pair #263 created successfully.\n",
      "✅ Baseline training pair #264 created successfully.\n",
      "✅ Baseline training pair #265 created successfully.\n",
      "✅ Baseline training pair #266 created successfully.\n",
      "✅ Baseline training pair #267 created successfully.\n",
      "✅ Baseline training pair #268 created successfully.\n",
      "✅ Baseline training pair #269 created successfully.\n",
      "✅ Baseline training pair #270 created successfully.\n",
      "✅ Baseline training pair #271 created successfully.\n",
      "✅ Baseline training pair #272 created successfully.\n",
      "✅ Baseline training pair #273 created successfully.\n",
      "✅ Baseline training pair #274 created successfully.\n",
      "✅ Baseline training pair #275 created successfully.\n",
      "✅ Baseline training pair #276 created successfully.\n",
      "✅ Baseline training pair #277 created successfully.\n",
      "✅ Baseline training pair #278 created successfully.\n",
      "✅ Baseline training pair #279 created successfully.\n",
      "✅ Baseline training pair #280 created successfully.\n",
      "✅ Baseline training pair #281 created successfully.\n",
      "✅ Baseline training pair #282 created successfully.\n",
      "✅ Baseline training pair #283 created successfully.\n",
      "✅ Baseline training pair #284 created successfully.\n",
      "✅ Baseline training pair #285 created successfully.\n",
      "✅ Baseline training pair #286 created successfully.\n",
      "✅ Baseline training pair #287 created successfully.\n",
      "✅ Baseline training pair #288 created successfully.\n",
      "✅ Baseline training pair #289 created successfully.\n",
      "✅ Baseline training pair #290 created successfully.\n",
      "✅ Baseline training pair #291 created successfully.\n",
      "✅ Baseline training pair #292 created successfully.\n",
      "✅ Baseline training pair #293 created successfully.\n",
      "✅ Baseline training pair #294 created successfully.\n",
      "✅ Baseline training pair #295 created successfully.\n",
      "✅ Baseline training pair #296 created successfully.\n",
      "✅ Baseline training pair #297 created successfully.\n",
      "✅ Baseline training pair #298 created successfully.\n",
      "✅ Baseline training pair #299 created successfully.\n",
      "✅ Baseline training pair #300 created successfully.\n",
      "✅ Baseline training pair #301 created successfully.\n",
      "✅ Baseline training pair #302 created successfully.\n",
      "✅ Baseline training pair #303 created successfully.\n",
      "✅ Baseline training pair #304 created successfully.\n",
      "✅ Baseline training pair #305 created successfully.\n",
      "✅ Baseline training pair #306 created successfully.\n",
      "✅ Baseline training pair #307 created successfully.\n",
      "✅ Baseline training pair #308 created successfully.\n",
      "✅ Baseline training pair #309 created successfully.\n",
      "✅ Baseline training pair #310 created successfully.\n",
      "✅ Baseline training pair #311 created successfully.\n",
      "✅ Baseline training pair #312 created successfully.\n",
      "✅ Baseline training pair #313 created successfully.\n",
      "✅ Baseline training pair #314 created successfully.\n",
      "✅ Baseline training pair #315 created successfully.\n",
      "✅ Baseline training pair #316 created successfully.\n",
      "✅ Baseline training pair #317 created successfully.\n",
      "✅ Baseline training pair #318 created successfully.\n",
      "✅ Baseline training pair #319 created successfully.\n",
      "✅ Baseline training pair #320 created successfully.\n",
      "✅ Baseline training pair #321 created successfully.\n",
      "✅ Baseline training pair #322 created successfully.\n",
      "✅ Baseline training pair #323 created successfully.\n",
      "✅ Baseline training pair #324 created successfully.\n",
      "✅ Baseline training pair #325 created successfully.\n",
      "✅ Baseline training pair #326 created successfully.\n",
      "✅ Baseline training pair #327 created successfully.\n",
      "✅ Baseline training pair #328 created successfully.\n",
      "✅ Baseline training pair #329 created successfully.\n",
      "✅ Baseline training pair #330 created successfully.\n",
      "✅ Baseline training pair #331 created successfully.\n",
      "✅ Baseline training pair #332 created successfully.\n",
      "✅ Baseline training pair #333 created successfully.\n",
      "✅ Baseline training pair #334 created successfully.\n",
      "✅ Baseline training pair #335 created successfully.\n",
      "✅ Baseline training pair #336 created successfully.\n",
      "✅ Baseline training pair #337 created successfully.\n",
      "✅ Baseline training pair #338 created successfully.\n",
      "✅ Baseline training pair #339 created successfully.\n",
      "✅ Baseline training pair #340 created successfully.\n",
      "✅ Baseline training pair #341 created successfully.\n",
      "✅ Baseline training pair #342 created successfully.\n",
      "✅ Baseline training pair #343 created successfully.\n",
      "✅ Baseline training pair #344 created successfully.\n",
      "✅ Baseline training pair #345 created successfully.\n",
      "✅ Baseline training pair #346 created successfully.\n",
      "✅ Baseline training pair #347 created successfully.\n",
      "✅ Baseline training pair #348 created successfully.\n",
      "✅ Baseline training pair #349 created successfully.\n",
      "✅ Baseline training pair #350 created successfully.\n",
      "✅ Baseline training pair #351 created successfully.\n",
      "✅ Baseline training pair #352 created successfully.\n",
      "✅ Baseline training pair #353 created successfully.\n",
      "✅ Baseline training pair #354 created successfully.\n",
      "✅ Baseline training pair #355 created successfully.\n",
      "✅ Baseline training pair #356 created successfully.\n",
      "✅ Baseline training pair #357 created successfully.\n",
      "✅ Baseline training pair #358 created successfully.\n",
      "✅ Baseline training pair #359 created successfully.\n",
      "✅ Baseline training pair #360 created successfully.\n",
      "✅ Baseline training pair #361 created successfully.\n",
      "✅ Baseline training pair #362 created successfully.\n",
      "✅ Baseline training pair #363 created successfully.\n",
      "✅ Baseline training pair #364 created successfully.\n",
      "✅ Baseline training pair #365 created successfully.\n",
      "✅ Baseline training pair #366 created successfully.\n",
      "✅ Baseline training pair #367 created successfully.\n",
      "✅ Baseline training pair #368 created successfully.\n",
      "✅ Baseline training pair #369 created successfully.\n",
      "✅ Baseline training pair #370 created successfully.\n",
      "✅ Baseline training pair #371 created successfully.\n",
      "✅ Baseline training pair #372 created successfully.\n",
      "✅ Baseline training pair #373 created successfully.\n",
      "✅ Baseline training pair #374 created successfully.\n",
      "✅ Baseline training pair #375 created successfully.\n",
      "✅ Baseline training pair #376 created successfully.\n",
      "✅ Baseline training pair #377 created successfully.\n",
      "✅ Baseline training pair #378 created successfully.\n",
      "✅ Baseline training pair #379 created successfully.\n",
      "✅ Baseline training pair #380 created successfully.\n",
      "✅ Baseline training pair #381 created successfully.\n",
      "✅ Baseline training pair #382 created successfully.\n",
      "✅ Baseline training pair #383 created successfully.\n",
      "✅ Baseline training pair #384 created successfully.\n",
      "✅ Baseline training pair #385 created successfully.\n",
      "✅ Baseline training pair #386 created successfully.\n",
      "✅ Baseline training pair #387 created successfully.\n",
      "✅ Baseline training pair #388 created successfully.\n",
      "✅ Baseline training pair #389 created successfully.\n",
      "✅ Baseline training pair #390 created successfully.\n",
      "✅ Baseline training pair #391 created successfully.\n",
      "✅ Baseline training pair #392 created successfully.\n",
      "✅ Baseline training pair #393 created successfully.\n",
      "✅ Baseline training pair #394 created successfully.\n",
      "✅ Baseline training pair #395 created successfully.\n",
      "✅ Baseline training pair #396 created successfully.\n",
      "✅ Baseline training pair #397 created successfully.\n",
      "✅ Baseline training pair #398 created successfully.\n",
      "✅ Baseline training pair #399 created successfully.\n",
      "✅ Baseline training pair #400 created successfully.\n",
      "✅ Baseline training pair #401 created successfully.\n",
      "✅ Baseline training pair #402 created successfully.\n",
      "✅ Baseline training pair #403 created successfully.\n",
      "✅ Baseline training pair #404 created successfully.\n",
      "✅ Baseline training pair #405 created successfully.\n",
      "✅ Baseline training pair #406 created successfully.\n",
      "✅ Baseline training pair #407 created successfully.\n",
      "✅ Baseline training pair #408 created successfully.\n",
      "✅ Baseline training pair #409 created successfully.\n",
      "✅ Baseline training pair #410 created successfully.\n",
      "✅ Baseline training pair #411 created successfully.\n",
      "✅ Baseline training pair #412 created successfully.\n",
      "✅ Baseline training pair #413 created successfully.\n",
      "✅ Baseline training pair #414 created successfully.\n",
      "✅ Baseline training pair #415 created successfully.\n",
      "✅ Baseline training pair #416 created successfully.\n",
      "✅ Baseline training pair #417 created successfully.\n",
      "✅ Baseline training pair #418 created successfully.\n",
      "✅ Baseline training pair #419 created successfully.\n",
      "✅ Baseline training pair #420 created successfully.\n",
      "✅ Baseline training pair #421 created successfully.\n",
      "✅ Baseline training pair #422 created successfully.\n",
      "✅ Baseline training pair #423 created successfully.\n",
      "✅ Baseline training pair #424 created successfully.\n",
      "✅ Baseline training pair #425 created successfully.\n",
      "✅ Baseline training pair #426 created successfully.\n",
      "✅ Baseline training pair #427 created successfully.\n",
      "✅ Baseline training pair #428 created successfully.\n",
      "✅ Baseline training pair #429 created successfully.\n",
      "✅ Baseline training pair #430 created successfully.\n",
      "✅ Baseline training pair #431 created successfully.\n",
      "✅ Baseline training pair #432 created successfully.\n",
      "✅ Baseline training pair #433 created successfully.\n",
      "✅ Baseline training pair #434 created successfully.\n",
      "✅ Baseline training pair #435 created successfully.\n",
      "✅ Baseline training pair #436 created successfully.\n",
      "✅ Baseline training pair #437 created successfully.\n",
      "✅ Baseline training pair #438 created successfully.\n",
      "✅ Baseline training pair #439 created successfully.\n",
      "✅ Baseline training pair #440 created successfully.\n",
      "✅ Baseline training pair #441 created successfully.\n",
      "✅ Baseline training pair #442 created successfully.\n",
      "✅ Baseline training pair #443 created successfully.\n",
      "✅ Baseline training pair #444 created successfully.\n",
      "✅ Baseline training pair #445 created successfully.\n",
      "✅ Baseline training pair #446 created successfully.\n",
      "✅ Baseline training pair #447 created successfully.\n",
      "✅ Baseline training pair #448 created successfully.\n",
      "✅ Baseline training pair #449 created successfully.\n",
      "✅ Baseline training pair #450 created successfully.\n",
      "✅ Baseline training pair #451 created successfully.\n",
      "✅ Baseline training pair #452 created successfully.\n",
      "✅ Baseline training pair #453 created successfully.\n",
      "✅ Baseline training pair #454 created successfully.\n",
      "✅ Baseline training pair #455 created successfully.\n",
      "✅ Baseline training pair #456 created successfully.\n",
      "✅ Baseline training pair #457 created successfully.\n",
      "✅ Baseline training pair #458 created successfully.\n",
      "✅ Baseline training pair #459 created successfully.\n",
      "✅ Baseline training pair #460 created successfully.\n",
      "✅ Baseline training pair #461 created successfully.\n",
      "✅ Baseline training pair #462 created successfully.\n",
      "✅ Baseline training pair #463 created successfully.\n",
      "✅ Baseline training pair #464 created successfully.\n",
      "✅ Baseline training pair #465 created successfully.\n",
      "✅ Baseline training pair #466 created successfully.\n",
      "✅ Baseline training pair #467 created successfully.\n",
      "✅ Baseline training pair #468 created successfully.\n",
      "✅ Baseline training pair #469 created successfully.\n",
      "✅ Baseline training pair #470 created successfully.\n",
      "✅ Baseline training pair #471 created successfully.\n",
      "✅ Baseline training pair #472 created successfully.\n",
      "✅ Baseline training pair #473 created successfully.\n",
      "✅ Baseline training pair #474 created successfully.\n",
      "✅ Baseline training pair #475 created successfully.\n",
      "✅ Baseline training pair #476 created successfully.\n",
      "✅ Baseline training pair #477 created successfully.\n",
      "✅ Baseline training pair #478 created successfully.\n",
      "✅ Baseline training pair #479 created successfully.\n",
      "✅ Baseline training pair #480 created successfully.\n",
      "✅ Baseline training pair #481 created successfully.\n",
      "✅ Baseline training pair #482 created successfully.\n",
      "✅ Baseline training pair #483 created successfully.\n",
      "✅ Baseline training pair #484 created successfully.\n",
      "✅ Baseline training pair #485 created successfully.\n",
      "✅ Baseline training pair #486 created successfully.\n",
      "✅ Baseline training pair #487 created successfully.\n",
      "✅ Baseline training pair #488 created successfully.\n",
      "✅ Baseline training pair #489 created successfully.\n",
      "✅ Baseline training pair #490 created successfully.\n",
      "✅ Baseline training pair #491 created successfully.\n",
      "✅ Baseline training pair #492 created successfully.\n",
      "✅ Baseline training pair #493 created successfully.\n",
      "✅ Baseline training pair #494 created successfully.\n",
      "✅ Baseline training pair #495 created successfully.\n",
      "✅ All training pairs have been successfully created.\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "baseline_training_data_generator(src_bucket = \"trusted-zone\", dest_bucket = \"training-data-construction-zone\",\n",
    "                                 collection = collection_texts_images, model_text = model, tokenizer=tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
