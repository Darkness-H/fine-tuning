{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c63c08-afe2-4f68-baeb-b7460dad4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful dependencies\n",
    "import boto3\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "# Set a seed for reproducibility\n",
    "SEED = 10721\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acec68ca-1d48-42b8-ade7-57873159f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup S3 client for MinIO (MinIO implements Amazon S3 API)\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://127.0.0.1:9000\", # MinIO API endpoint\n",
    "    aws_access_key_id=\"minioadmin\", # User name\n",
    "    aws_secret_access_key=\"minioadmin\", # Password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bebef6fa-639a-4abc-96d8-0009b91d6afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'training-data-construction-zone' already exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '187A105602831645',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-checksum-crc32': 'AAAAAA==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '187A105602831645',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '2109',\n",
       "   'x-ratelimit-remaining': '2109',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Fri, 21 Nov 2025 15:49:25 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       " 'ChecksumCRC32': 'AAAAAA==',\n",
       " 'ChecksumType': 'FULL_OBJECT'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a new Bucket in Min-IO to store our augmented data\n",
    "\n",
    "# List existing buckets\n",
    "buckets = [b[\"Name\"] for b in s3.list_buckets()[\"Buckets\"]]\n",
    "\n",
    "# Function that given a name, creates a bucket\n",
    "def createBucket(name, list_buckets):\n",
    "    if name in list_buckets:\n",
    "        print(f\"Bucket '{name}' already exists!\")\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=name)\n",
    "        print(f\"Created bucket: {name}\")\n",
    "\n",
    "# Create a bucket named landing_zone\n",
    "createBucket(\"training-data-construction-zone\", buckets)\n",
    "# Sub-bucket: Baseline Training Data\n",
    "s3.put_object(Bucket=\"training-data-construction-zone\", Key=\"images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17b0065-fdea-488d-9a4c-31247d33e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this function to retrieve an image from our bucket in PIL Image format\n",
    "def get_image(bucket, key):\n",
    "    resp = s3.get_object(Bucket=bucket, Key=key)\n",
    "    body = resp[\"Body\"].read()\n",
    "    img = Image.open(BytesIO(body))\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e09862d-396f-47a2-921c-af35190ef8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize helper used after cropping\n",
    "resize_to_512 = transforms.Resize((512, 512))  # resize image to 512x512 pixels\n",
    "def generate_and_save_augmented(\n",
    "    transformer,            # any callable that takes a PIL image and returns a PIL image\n",
    "    suffix: str,            # suffix to distinguish different augmentations, e.g. \"hflip\", \"vflip\", \"crop\"\n",
    "    image: Image.Image,     # original PIL image to be augmented\n",
    "    dest_bucket: str,       # name of the destination S3 bucket\n",
    "    dest_prefix: str,       # prefix (folder path) inside the bucket, e.g. \"augmented/\"\n",
    "    new_key_infix: str,     # main part of the file name (usually derived from the original key)\n",
    "):\n",
    "    # apply the augmentation to the input image\n",
    "    if suffix == \"crop\":\n",
    "        # For random crops we sample a region per image, so we capture the crop parameters to know exactly what was applied.\n",
    "        # sample crop params\n",
    "        i, j, h, w = transformer.get_params(image, output_size=transformer.size)\n",
    "        # apply crop manually\n",
    "        aug_image = TF.crop(image, i, j, h, w)\n",
    "        # resize back to 512x512\n",
    "        aug_image = resize_to_512(aug_image)\n",
    "        print(\n",
    "            f\"[{new_key_infix}]: [crop] cropped region - top={i}, left={j}, \"\n",
    "            f\"height={h}, width={w}\"\n",
    "        )\n",
    "    else:\n",
    "        # For flips we always apply the transform (p=1.0), so the behavior is deterministic for each image.\n",
    "        aug_image = transformer(image)\n",
    "        print(f\"[{new_key_infix}]: [{suffix}] augmentation applied by transformer.\")\n",
    "\n",
    "    # build the new S3 object key, e.g. \"images/image000123_hflip.png\"\n",
    "    augment_key = f\"{dest_prefix}{new_key_infix}_{suffix}.png\"\n",
    "\n",
    "    # serialize PIL image to bytes (in-memory buffer) as PNG\n",
    "    buffer = BytesIO()\n",
    "    aug_image.save(buffer, format=\"PNG\")\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # upload the augmented image bytes to S3\n",
    "    s3.upload_fileobj(\n",
    "        buffer,\n",
    "        Bucket=dest_bucket,\n",
    "        Key=augment_key,\n",
    "        ExtraArgs={\"ContentType\": \"image/png\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f71459d-1cb3-4eb8-8ff8-367465fd6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation(src_bucket, dest_bucket, dest_prefix=\"images/\"):\n",
    "    id_counter = 0\n",
    "    \n",
    "    # define individual image augmentations\n",
    "    hflip_transform = transforms.RandomHorizontalFlip(p=1.0)  # always flip image horizontally (left-right)\n",
    "    vflip_transform = transforms.RandomVerticalFlip(p=1.0)    # always flip image vertically (top-bottom)\n",
    "\n",
    "    # random crop \n",
    "    crop_transform = transforms.RandomCrop(400) # randomly crop a 400x400 patch from the original image\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\") # It returns objects in pages and not all at once.\n",
    "    for page in paginator.paginate(Bucket=src_bucket, Prefix=\"baseline-training-data/\"):\n",
    "\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "\n",
    "            if \"image\" in key:\n",
    "                # get image\n",
    "                image = get_image(src_bucket,key)\n",
    "                # new key of image\n",
    "                new_key_infix = key.split(\"/\")[1].split(\".\")[0]\n",
    "                new_key = dest_prefix + new_key_infix + \".png\"\n",
    "                copy_source_text = {\"Bucket\": src_bucket, \"Key\": key}\n",
    "                s3.copy_object(Bucket=dest_bucket, Key=new_key, CopySource=copy_source_text)\n",
    "\n",
    "                #generate image flip horizontally\n",
    "                generate_and_save_augmented(hflip_transform,\"x_rotate\",image,dest_bucket,dest_prefix,new_key_infix)\n",
    "                #generate image flip vertically\n",
    "                generate_and_save_augmented(vflip_transform,\"y_rotate\",image,dest_bucket,dest_prefix,new_key_infix)\n",
    "                #generate image cropped\n",
    "                generate_and_save_augmented(crop_transform,\"crop\",image,dest_bucket,dest_prefix,new_key_infix)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4aa2f-8ef4-4b90-a153-e5cb9b710e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[image_000001]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000001]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000001]: [crop] cropped region - top=1, left=60, height=400, width=400\n",
      "[image_000002]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000002]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000002]: [crop] cropped region - top=12, left=86, height=400, width=400\n",
      "[image_000003]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000003]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000003]: [crop] cropped region - top=8, left=87, height=400, width=400\n",
      "[image_000004]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000004]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000004]: [crop] cropped region - top=108, left=83, height=400, width=400\n",
      "[image_000005]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000005]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000005]: [crop] cropped region - top=94, left=111, height=400, width=400\n",
      "[image_000006]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000006]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000006]: [crop] cropped region - top=0, left=8, height=400, width=400\n",
      "[image_000007]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000007]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000007]: [crop] cropped region - top=56, left=10, height=400, width=400\n",
      "[image_000008]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000008]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000008]: [crop] cropped region - top=65, left=99, height=400, width=400\n",
      "[image_000009]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000009]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000009]: [crop] cropped region - top=81, left=19, height=400, width=400\n",
      "[image_000010]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000010]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000010]: [crop] cropped region - top=39, left=106, height=400, width=400\n",
      "[image_000011]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000011]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000011]: [crop] cropped region - top=45, left=80, height=400, width=400\n",
      "[image_000012]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000012]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000012]: [crop] cropped region - top=91, left=38, height=400, width=400\n",
      "[image_000013]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000013]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000013]: [crop] cropped region - top=77, left=60, height=400, width=400\n",
      "[image_000014]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000014]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000014]: [crop] cropped region - top=94, left=8, height=400, width=400\n",
      "[image_000015]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000015]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000015]: [crop] cropped region - top=25, left=21, height=400, width=400\n",
      "[image_000016]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000016]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000016]: [crop] cropped region - top=84, left=91, height=400, width=400\n",
      "[image_000017]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000017]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000017]: [crop] cropped region - top=64, left=80, height=400, width=400\n",
      "[image_000018]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000018]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000018]: [crop] cropped region - top=3, left=11, height=400, width=400\n",
      "[image_000019]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000019]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000019]: [crop] cropped region - top=75, left=97, height=400, width=400\n",
      "[image_000020]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000020]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000020]: [crop] cropped region - top=0, left=10, height=400, width=400\n",
      "[image_000021]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000021]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000021]: [crop] cropped region - top=86, left=108, height=400, width=400\n",
      "[image_000022]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000022]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000022]: [crop] cropped region - top=26, left=70, height=400, width=400\n",
      "[image_000023]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000023]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000023]: [crop] cropped region - top=4, left=68, height=400, width=400\n",
      "[image_000024]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000024]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000024]: [crop] cropped region - top=60, left=84, height=400, width=400\n",
      "[image_000025]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000025]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000025]: [crop] cropped region - top=34, left=93, height=400, width=400\n",
      "[image_000026]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000026]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000026]: [crop] cropped region - top=89, left=31, height=400, width=400\n",
      "[image_000027]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000027]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000027]: [crop] cropped region - top=51, left=32, height=400, width=400\n",
      "[image_000028]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000028]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000028]: [crop] cropped region - top=25, left=85, height=400, width=400\n",
      "[image_000029]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000029]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000029]: [crop] cropped region - top=16, left=43, height=400, width=400\n",
      "[image_000030]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000030]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000030]: [crop] cropped region - top=104, left=101, height=400, width=400\n",
      "[image_000031]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000031]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000031]: [crop] cropped region - top=72, left=18, height=400, width=400\n",
      "[image_000032]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000032]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000032]: [crop] cropped region - top=2, left=26, height=400, width=400\n",
      "[image_000033]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000033]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000033]: [crop] cropped region - top=34, left=58, height=400, width=400\n",
      "[image_000034]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000034]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000034]: [crop] cropped region - top=43, left=1, height=400, width=400\n",
      "[image_000035]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000035]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000035]: [crop] cropped region - top=51, left=69, height=400, width=400\n",
      "[image_000036]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000036]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000036]: [crop] cropped region - top=58, left=89, height=400, width=400\n",
      "[image_000037]: [x_rotate] augmentation applied by transformer.\n",
      "[image_000037]: [y_rotate] augmentation applied by transformer.\n",
      "[image_000037]: [crop] cropped region - top=58, left=100, height=400, width=400\n"
     ]
    }
   ],
   "source": [
    "image_augmentation(src_bucket = \"training-data-construction-zone\", dest_bucket = \"training-data-construction-zone\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
