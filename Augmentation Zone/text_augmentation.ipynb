{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1513906-5c7c-4525-abc1-0067f560c81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/60/90/81ac364ef94209c100e12579629dc92bf7a709a84af32f8c551b02c07e94/nltk-3.9.2-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in d:\\multi-modal-management-pipeline\\.venv\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in d:\\multi-modal-management-pipeline\\.venv\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\multi-modal-management-pipeline\\.venv\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in d:\\multi-modal-management-pipeline\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\multi-modal-management-pipeline\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 10.7 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install nlpaug\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eba5bec-aa97-45d6-ad6a-492a2e432f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful dependencies\n",
    "import boto3\n",
    "import re\n",
    "import random\n",
    "from typing import List\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import torch\n",
    "import open_clip\n",
    "import numpy as np\n",
    "# Set a seed for reproducibility\n",
    "SEED = 10721\n",
    "random.seed(SEED) \n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6150ca19-7cf1-4cba-b9ff-ffd20cfd4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup S3 client for MinIO (MinIO implements Amazon S3 API)\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://127.0.0.1:9000\", # MinIO API endpoint\n",
    "    aws_access_key_id=\"minioadmin\", # User name\n",
    "    aws_secret_access_key=\"minioadmin\", # Password\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053b671e-4df8-4153-a454-cd1e1000b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'training-data-construction-zone' already exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '187A0F2DA625D69D',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-checksum-crc32': 'AAAAAA==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '187A0F2DA625D69D',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '2109',\n",
       "   'x-ratelimit-remaining': '2109',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Fri, 21 Nov 2025 15:28:12 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       " 'ChecksumCRC32': 'AAAAAA==',\n",
       " 'ChecksumType': 'FULL_OBJECT'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a new Bucket in Min-IO to store our augmented data\n",
    "\n",
    "# List existing buckets\n",
    "buckets = [b[\"Name\"] for b in s3.list_buckets()[\"Buckets\"]]\n",
    "\n",
    "# Function that given a name, creates a bucket\n",
    "def createBucket(name, list_buckets):\n",
    "    if name in list_buckets:\n",
    "        print(f\"Bucket '{name}' already exists!\")\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=name)\n",
    "        print(f\"Created bucket: {name}\")\n",
    "\n",
    "# Create a bucket named landing_zone\n",
    "createBucket(\"training-data-construction-zone\", buckets)\n",
    "# Sub-bucket: Baseline Training Data\n",
    "s3.put_object(Bucket=\"training-data-construction-zone\", Key=\"texts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf5e4b2-bfd7-43e9-919e-ecf30285e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(bucket, key):\n",
    "    resp = s3.get_object(Bucket=bucket, Key=key)\n",
    "    body = resp[\"Body\"].read()\n",
    "    text = body.decode(\"utf-8\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ddd73f5-2f19-427f-8e3f-ae53f84a259b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-23): 24 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 768)\n",
       "  (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just in case our device has gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load model\n",
    "model, _, _ = open_clip.create_model_and_transforms(\"hf-hub:laion/CLIP-ViT-L-14-laion2B-s32B-b82K\")\n",
    "tokenizer = open_clip.get_tokenizer(\"hf-hub:laion/CLIP-ViT-L-14-laion2B-s32B-b82K\") # Tokenizer for texts\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d6eedd-e573-42a8-8ccf-d449c481ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "# The next function returns the embedding of the given text\n",
    "def embed_text(model, tokenizer, texts: str):\n",
    "    tokens = tokenizer([texts]).to(device) # tokenized batch\n",
    "    feats = model.encode_text(tokens)\n",
    "    feats = feats / feats.norm(dim=-1, keepdim=True) # normalize\n",
    "    return feats.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf8737f8-3101-42de-a661-9d0e155e18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Very simple tokenizer for English-like text.\n",
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
    "\n",
    "#  Simple detokenizer matching simple_tokenize.\n",
    "def detokenize(tokens: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Simple detokenizer matching simple_tokenize.\n",
    "    \"\"\"\n",
    "    text = \" \".join(tokens)\n",
    "    text = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beba5fcb-2c1a-4c49-8adc-ce9e8ac759e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete each token with probability p.\n",
    "def random_deletion(tokens: List[str], p: float = 0.1) -> List[str]:\n",
    "    if len(tokens) == 1:\n",
    "        return tokens\n",
    "\n",
    "    kept = [t for t in tokens if random.random() > p]\n",
    "    if not kept:\n",
    "        kept.append(random.choice(tokens))\n",
    "    return kept\n",
    "\n",
    "# Randomly swap a small portion of tokens.\n",
    "def random_swap(tokens: List[str], ratio: float = 0.05) -> list[str]:\n",
    "    n = len(tokens)\n",
    "    if n < 2:\n",
    "        return tokens\n",
    "\n",
    "    n_swaps = max(1, int(ratio * n))\n",
    "\n",
    "    for _ in range(n_swaps):\n",
    "        i, j = random.sample(range(n), 2)\n",
    "        tokens[i], tokens[j] = tokens[j], tokens[i]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1120357c-8dbe-4d31-9c0d-99621f943ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "# Introduce a simple spelling error in a single word\n",
    "def corrupt_word(word: str) -> str:\n",
    "    if len(word) == 0:\n",
    "        return word\n",
    "\n",
    "    op = random.choice([\"delete\", \"substitute\", \"duplicate\"])\n",
    "\n",
    "    if op == \"delete\" and len(word) > 1:\n",
    "        pos = random.randrange(len(word))\n",
    "        return word[:pos] + word[pos+1:]\n",
    "\n",
    "    if op == \"substitute\":\n",
    "        pos = random.randrange(len(word))\n",
    "        new_char = random.choice(ALPHABET)\n",
    "        return word[:pos] + new_char + word[pos+1:]\n",
    "\n",
    "    if op == \"duplicate\":\n",
    "        pos = random.randrange(len(word))\n",
    "        return word[:pos] + word[pos] + word[pos:]\n",
    "\n",
    "    return word\n",
    "\n",
    "# For each alphabetical token, apply a spelling error with probability p.\n",
    "def random_spelling_error(tokens: List[str], p: float = 0.1) -> List[str]:\n",
    "    new_tokens = []\n",
    "    for t in tokens:\n",
    "        if t.isalpha() and random.random() < p:\n",
    "            new_tokens.append(corrupt_word(t))\n",
    "        else:\n",
    "            new_tokens.append(t)\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c10e2da8-afbb-4ce2-a2fe-51829438e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect synonyms from WordNet (very naive).\n",
    "def get_synonyms(word: str) -> List[str]:\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "            if lemma_name.lower() != word.lower():\n",
    "                synonyms.add(lemma_name)\n",
    "    return list(synonyms)\n",
    "\n",
    "# Randomly choose a small portion of tokens and replace them with synonyms.\n",
    "def random_synonym_replacement(tokens: List[str], ratio: float = 0.05) -> List[str]:\n",
    "    n = len(tokens)\n",
    "    n_replacements = max(1, int(ratio * n))\n",
    "    candidate_indices = [\n",
    "        i for i, t in enumerate(tokens)\n",
    "        if t.isalpha() and len(t) > 2  # skip punctuation & very short tokens\n",
    "    ]\n",
    "    if not candidate_indices:\n",
    "        return tokens\n",
    "\n",
    "    indices = random.sample(candidate_indices, n_replacements)\n",
    "\n",
    "    for idx in indices:\n",
    "        word = tokens[idx]\n",
    "        syns = get_synonyms(word)\n",
    "        if syns:\n",
    "            tokens[idx] = random.choice(syns)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "347b74b5-1bf5-49f8-95ff-8e9853b296dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(method,text,ratio = 0.1):\n",
    "    tokens = simple_tokenize(text)\n",
    "    if (method == \"swap_spelling_aug\"):\n",
    "        # We apply two augmentations, so we halve the ratio for each one.\n",
    "        ratio = ratio / 2\n",
    "        tokens = random_spelling_error(tokens,ratio)\n",
    "        tokens = random_swap(tokens,ratio)\n",
    "\n",
    "    elif (method == \"delete_aug\"):\n",
    "        tokens = random_deletion(tokens, ratio)\n",
    "\n",
    "    elif (method == \"swap_sym_word_aug\"):\n",
    "        # We apply two augmentations, so we halve the ratio for each one.\n",
    "        ratio = ratio / 2\n",
    "        tokens = random_synonym_replacement(tokens,ratio)\n",
    "        tokens = random_swap(tokens,ratio) \n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown augmentation method: {method}\")\n",
    "\n",
    "    return detokenize(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3662ff-d583-4b72-9eba-bc5552acb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate an augmented version of original text and save the reuslt to S3\n",
    "def generate_and_save_augmented(\n",
    "    suffix: str,\n",
    "    body: str,\n",
    "    embedded_orig: np.ndarray,\n",
    "    model_text,\n",
    "    tokenizer,\n",
    "    dest_bucket: str,\n",
    "    dest_prefix: str,\n",
    "    new_key_infix: str,\n",
    "    max_try: int = 10,\n",
    "    min_sim_accept: float = 0.9,\n",
    "    max_sim_accept: float = 0.99,\n",
    "):\n",
    "    best_text = None\n",
    "    best_sim = -1.0\n",
    "\n",
    "    for attempt in range(max_try):\n",
    "        # 1. Generate augmented text\n",
    "        aug_text = augment(suffix,body)\n",
    "        \n",
    "        # 2. Compute cosine similarity with the original text embedding\n",
    "        emb_aug = embed_text(model_text, tokenizer, aug_text)\n",
    "        sim = float(np.dot(embedded_orig, emb_aug))\n",
    "        \n",
    "\n",
    "        # Track the best candidate regardless of whether it is in the range\n",
    "        if sim > best_sim and sim < max_sim_accept:\n",
    "            best_sim = sim\n",
    "            best_text = aug_text\n",
    "\n",
    "        elif sim < abs(best_sim) and  sim > max_sim_accept:\n",
    "            best_sim = sim\n",
    "            best_text = aug_text\n",
    "\n",
    "        # If similarity is within the acceptable range, save and return early\n",
    "        if min_sim_accept <= sim <= max_sim_accept:\n",
    "            augment_key = f\"{dest_prefix}{new_key_infix}_{suffix}.txt\"\n",
    "            s3.put_object(\n",
    "                Bucket=dest_bucket,\n",
    "                Key=augment_key,\n",
    "                Body=aug_text.encode(\"utf-8\"),\n",
    "                ContentType=\"text/plain\",\n",
    "            )\n",
    "            print(f\"{new_key_infix}: [{suffix}] attempt {attempt + 1}, sim={sim:.4f}\")\n",
    "            return best_sim\n",
    "\n",
    "    # If no candidate falls into [min_sim_accept, max_sim_accept],\n",
    "    # use the best candidate found as a fallback.\n",
    "    if best_text is not None:\n",
    "        augment_key = f\"{dest_prefix}{new_key_infix}_{suffix}.txt\"\n",
    "        print(f\"{new_key_infix}: [{suffix}] use best_sim={best_sim:.4f} as fallback\")\n",
    "        s3.put_object(\n",
    "            Bucket=dest_bucket,\n",
    "            Key=augment_key,\n",
    "            Body=best_text.encode(\"utf-8\"),\n",
    "            ContentType=\"text/plain\",\n",
    "        )\n",
    "\n",
    "    return best_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bc29d-ef67-4156-a00e-aa30dc3c7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_augmentation(src_bucket, dest_bucket, model_text, tokenizer, dest_prefix=\"texts/\"):\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\") # It returns objects in pages and not all at once.\n",
    "    for page in paginator.paginate(Bucket=src_bucket, Prefix=\"baseline-training-data/\"):\n",
    "\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "\n",
    "            if \"text\" in key:\n",
    "                body = get_text(src_bucket, key)\n",
    "                embedded = embed_text(model_text,tokenizer,body)\n",
    "                new_key_infix = key.split(\"/\")[1].split(\".\")[0]\n",
    "                new_key = dest_prefix + new_key_infix + \".txt\"\n",
    "                copy_source_text = {\"Bucket\": src_bucket, \"Key\": key}\n",
    "                s3.copy_object(Bucket=dest_bucket, Key=new_key, CopySource=copy_source_text)\n",
    "                \n",
    "                # word-level insert spelling error\n",
    "                generate_and_save_augmented(\n",
    "                    suffix=\"swap_spelling_aug\",\n",
    "                    body=body,\n",
    "                    embedded_orig=embedded,\n",
    "                    model_text=model_text,\n",
    "                    tokenizer=tokenizer,\n",
    "                    dest_bucket=dest_bucket,\n",
    "                    dest_prefix=dest_prefix,\n",
    "                    new_key_infix=new_key_infix,\n",
    "                    max_try=10,\n",
    "                    min_sim_accept=0.9,\n",
    "                    max_sim_accept=0.99,\n",
    "                )\n",
    "    \n",
    "                # 2) Word-level delete\n",
    "                generate_and_save_augmented(\n",
    "                    suffix=\"delete_aug\",\n",
    "                    body=body,\n",
    "                    embedded_orig=embedded,\n",
    "                    model_text=model_text,\n",
    "                    tokenizer=tokenizer,\n",
    "                    dest_bucket=dest_bucket,\n",
    "                    dest_prefix=dest_prefix,\n",
    "                    new_key_infix=new_key_infix,\n",
    "                    max_try=10,\n",
    "                    min_sim_accept=0.9,\n",
    "                    max_sim_accept=0.99,\n",
    "                )\n",
    "    \n",
    "                # 3) Word-level swap + synonym\n",
    "                generate_and_save_augmented(\n",
    "                    suffix=\"swap_sym_word_aug\",\n",
    "                    body=body,\n",
    "                    embedded_orig=embedded,\n",
    "                    model_text=model_text,\n",
    "                    tokenizer=tokenizer,\n",
    "                    dest_bucket=dest_bucket,\n",
    "                    dest_prefix=dest_prefix,\n",
    "                    new_key_infix=new_key_infix,\n",
    "                    max_try=10,\n",
    "                    min_sim_accept=0.9,\n",
    "                    max_sim_accept=0.99,\n",
    "                )\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca68a8f-e457-433c-a53c-f6e40b3bbcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[swap_spelling_aug] attempt 1, sim=0.9852\n",
      "[delete_aug] attempt 1, sim=0.9676\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9817\n",
      "[swap_spelling_aug] attempt 1, sim=0.9198\n",
      "[delete_aug] attempt 1, sim=0.9728\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9633\n",
      "[swap_spelling_aug] attempt 1, sim=0.9626\n",
      "[delete_aug] attempt 2, sim=0.9776\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9887\n",
      "[swap_spelling_aug] attempt 2, sim=0.9316\n",
      "[delete_aug] attempt 1, sim=0.9767\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9652\n",
      "[swap_spelling_aug] attempt 1, sim=0.9748\n",
      "[delete_aug] attempt 7, sim=0.9853\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9017\n",
      "[swap_spelling_aug] attempt 1, sim=0.9744\n",
      "[delete_aug] attempt 2, sim=0.9857\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9794\n",
      "[swap_spelling_aug] attempt 2, sim=0.9807\n",
      "[delete_aug] attempt 1, sim=0.9381\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9324\n",
      "[swap_spelling_aug] attempt 1, sim=0.9502\n",
      "[delete_aug] attempt 1, sim=0.9519\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9434\n",
      "[swap_spelling_aug] attempt 2, sim=0.9871\n",
      "[delete_aug] attempt 1, sim=0.9899\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9880\n",
      "[swap_spelling_aug] attempt 1, sim=0.9040\n",
      "[delete_aug] attempt 2, sim=0.9090\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9745\n",
      "[swap_spelling_aug] attempt 1, sim=0.9631\n",
      "[delete_aug] attempt 1, sim=0.9745\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9427\n",
      "[swap_spelling_aug] attempt 2, sim=0.9528\n",
      "[delete_aug] attempt 1, sim=0.9656\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9688\n",
      "[swap_spelling_aug] attempt 1, sim=0.9640\n",
      "[delete_aug] attempt 1, sim=0.9768\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9834\n",
      "[swap_spelling_aug] attempt 2, sim=0.9686\n",
      "[delete_aug] attempt 1, sim=0.9845\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9603\n",
      "[swap_spelling_aug] attempt 1, sim=0.9238\n",
      "[delete_aug] attempt 1, sim=0.9784\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9649\n",
      "[swap_spelling_aug] attempt 1, sim=0.9806\n",
      "[delete_aug] attempt 1, sim=0.9309\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9554\n",
      "[swap_spelling_aug] attempt 1, sim=0.9231\n",
      "[delete_aug] attempt 1, sim=0.9891\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9402\n",
      "[swap_spelling_aug] attempt 1, sim=0.9537\n",
      "[delete_aug] attempt 2, sim=0.9839\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9808\n",
      "[swap_spelling_aug] attempt 3, sim=0.9634\n",
      "[delete_aug] attempt 1, sim=0.9597\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9407\n",
      "[swap_spelling_aug] attempt 1, sim=0.9838\n",
      "[delete_aug] attempt 2, sim=0.9830\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9555\n",
      "[swap_spelling_aug] attempt 1, sim=0.9352\n",
      "[delete_aug] attempt 1, sim=0.9318\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9386\n",
      "[swap_spelling_aug] attempt 1, sim=0.9492\n",
      "[delete_aug] attempt 1, sim=0.9860\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9246\n",
      "[swap_spelling_aug] attempt 1, sim=0.9646\n",
      "[delete_aug] attempt 1, sim=0.9786\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9583\n",
      "[swap_spelling_aug] attempt 1, sim=0.9291\n",
      "[delete_aug] attempt 1, sim=0.9106\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9715\n",
      "[swap_spelling_aug] attempt 1, sim=0.9555\n",
      "[delete_aug] attempt 1, sim=0.9851\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9877\n",
      "[swap_spelling_aug] attempt 1, sim=0.9209\n",
      "[delete_aug] attempt 2, sim=0.9470\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9516\n",
      "[swap_spelling_aug] attempt 1, sim=0.9190\n",
      "[delete_aug] attempt 5, sim=0.9258\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9586\n",
      "[swap_spelling_aug] attempt 1, sim=0.9803\n",
      "[delete_aug] attempt 1, sim=0.9709\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9437\n",
      "[swap_spelling_aug] attempt 1, sim=0.9295\n",
      "[delete_aug] attempt 1, sim=0.9872\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9037\n",
      "[swap_spelling_aug] attempt 2, sim=0.9446\n",
      "[delete_aug] attempt 1, sim=0.9836\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9438\n",
      "[swap_spelling_aug] attempt 2, sim=0.9573\n",
      "[delete_aug] attempt 1, sim=0.9839\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9811\n",
      "[swap_spelling_aug] attempt 1, sim=0.9518\n",
      "[delete_aug] attempt 1, sim=0.9789\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9816\n",
      "[swap_spelling_aug] attempt 1, sim=0.9412\n",
      "[delete_aug] attempt 2, sim=0.9782\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9574\n",
      "[swap_spelling_aug] attempt 1, sim=0.9032\n",
      "[delete_aug] attempt 1, sim=0.9893\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9265\n",
      "[swap_spelling_aug] attempt 1, sim=0.9705\n",
      "[delete_aug] attempt 2, sim=0.9811\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9354\n",
      "[swap_spelling_aug] attempt 1, sim=0.9732\n",
      "[delete_aug] attempt 1, sim=0.9881\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9678\n",
      "[swap_spelling_aug] attempt 1, sim=0.9588\n",
      "[delete_aug] attempt 2, sim=0.9073\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9891\n",
      "[swap_spelling_aug] attempt 1, sim=0.9211\n",
      "[delete_aug] attempt 4, sim=0.9861\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9052\n",
      "[swap_spelling_aug] attempt 1, sim=0.9439\n",
      "[delete_aug] attempt 1, sim=0.9549\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9539\n",
      "[swap_spelling_aug] attempt 1, sim=0.9694\n",
      "[delete_aug] attempt 1, sim=0.9703\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9801\n",
      "[swap_spelling_aug] attempt 2, sim=0.9215\n",
      "[delete_aug] attempt 1, sim=0.9167\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9459\n",
      "[swap_spelling_aug] attempt 2, sim=0.9147\n",
      "[delete_aug] attempt 1, sim=0.9697\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9111\n",
      "[swap_spelling_aug] attempt 1, sim=0.9497\n",
      "[delete_aug] attempt 1, sim=0.9616\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9662\n",
      "[swap_spelling_aug] attempt 2, sim=0.9402\n",
      "[delete_aug] attempt 1, sim=0.9814\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9617\n",
      "[swap_spelling_aug] attempt 1, sim=0.9192\n",
      "[delete_aug] attempt 1, sim=0.9856\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9684\n",
      "[swap_spelling_aug] attempt 2, sim=0.9331\n",
      "[delete_aug] attempt 1, sim=0.9721\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9258\n",
      "[swap_spelling_aug] attempt 1, sim=0.9721\n",
      "[delete_aug] attempt 1, sim=0.9778\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9839\n",
      "[swap_spelling_aug] attempt 1, sim=0.9596\n",
      "[delete_aug] attempt 1, sim=0.9491\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9866\n",
      "[swap_spelling_aug] attempt 1, sim=0.9786\n",
      "[delete_aug] attempt 1, sim=0.9343\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9556\n",
      "[swap_spelling_aug] attempt 1, sim=0.9594\n",
      "[delete_aug] attempt 1, sim=0.9895\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9663\n",
      "[swap_spelling_aug] attempt 1, sim=0.9582\n",
      "[delete_aug] attempt 1, sim=0.9489\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9230\n",
      "[swap_spelling_aug] attempt 2, sim=0.9541\n",
      "[delete_aug] attempt 1, sim=0.9094\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9155\n",
      "[swap_spelling_aug] attempt 3, sim=0.9054\n",
      "[delete_aug] attempt 1, sim=0.9578\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9438\n",
      "[swap_spelling_aug] attempt 2, sim=0.9575\n",
      "[delete_aug] attempt 1, sim=0.9359\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9641\n",
      "[swap_spelling_aug] attempt 1, sim=0.9104\n",
      "[delete_aug] attempt 2, sim=0.9888\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9674\n",
      "[swap_spelling_aug] attempt 1, sim=0.9770\n",
      "[delete_aug] attempt 1, sim=0.9471\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9124\n",
      "[swap_spelling_aug] attempt 1, sim=0.9647\n",
      "[delete_aug] attempt 1, sim=0.9342\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9835\n",
      "[swap_spelling_aug] attempt 1, sim=0.9568\n",
      "[delete_aug] attempt 1, sim=0.9298\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9639\n",
      "[swap_spelling_aug] attempt 2, sim=0.9789\n",
      "[delete_aug] attempt 1, sim=0.9842\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9397\n",
      "[swap_spelling_aug] attempt 1, sim=0.9733\n",
      "[delete_aug] attempt 3, sim=0.9818\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9580\n",
      "[swap_spelling_aug] attempt 1, sim=0.9627\n",
      "[delete_aug] attempt 1, sim=0.9677\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9788\n",
      "[swap_spelling_aug] attempt 3, sim=0.9245\n",
      "[delete_aug] attempt 2, sim=0.9578\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9038\n",
      "[swap_spelling_aug] attempt 1, sim=0.9755\n",
      "[delete_aug] attempt 2, sim=0.9757\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9041\n",
      "[swap_spelling_aug] attempt 1, sim=0.9510\n",
      "[delete_aug] attempt 1, sim=0.9681\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9352\n",
      "[swap_spelling_aug] attempt 1, sim=0.9191\n",
      "[delete_aug] attempt 1, sim=0.9882\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9817\n",
      "[swap_spelling_aug] attempt 1, sim=0.9015\n",
      "[delete_aug] attempt 1, sim=0.9637\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9565\n",
      "[swap_spelling_aug] attempt 1, sim=0.9354\n",
      "[delete_aug] attempt 1, sim=0.9751\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9706\n",
      "[swap_spelling_aug] attempt 1, sim=0.9020\n",
      "[delete_aug] attempt 1, sim=0.9624\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9214\n",
      "[swap_spelling_aug] attempt 2, sim=0.9384\n",
      "[delete_aug] attempt 1, sim=0.9592\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9798\n",
      "[swap_spelling_aug] attempt 1, sim=0.9552\n",
      "[delete_aug] attempt 1, sim=0.9356\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9658\n",
      "[swap_spelling_aug] attempt 1, sim=0.9547\n",
      "[delete_aug] attempt 1, sim=0.9643\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9086\n",
      "[swap_spelling_aug] attempt 1, sim=0.9573\n",
      "[delete_aug] attempt 1, sim=0.9868\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9039\n",
      "[swap_spelling_aug] attempt 1, sim=0.9685\n",
      "[delete_aug] attempt 1, sim=0.9082\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9597\n",
      "[swap_spelling_aug] attempt 1, sim=0.9460\n",
      "[delete_aug] attempt 1, sim=0.9508\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9384\n",
      "[swap_spelling_aug] attempt 2, sim=0.9336\n",
      "[delete_aug] attempt 1, sim=0.9393\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9702\n",
      "[swap_spelling_aug] attempt 1, sim=0.9164\n",
      "[delete_aug] attempt 1, sim=0.9729\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9626\n",
      "[swap_spelling_aug] attempt 1, sim=0.9569\n",
      "[delete_aug] attempt 1, sim=0.9412\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9335\n",
      "[swap_spelling_aug] attempt 2, sim=0.9472\n",
      "[delete_aug] attempt 1, sim=0.9707\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9355\n",
      "[swap_spelling_aug] attempt 1, sim=0.9837\n",
      "[delete_aug] attempt 1, sim=0.9719\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9797\n",
      "[swap_spelling_aug] attempt 1, sim=0.9357\n",
      "[delete_aug] attempt 1, sim=0.9584\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9757\n",
      "[swap_spelling_aug] attempt 1, sim=0.9746\n",
      "[delete_aug] attempt 1, sim=0.9188\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9249\n",
      "[swap_spelling_aug] attempt 2, sim=0.9182\n",
      "[delete_aug] attempt 1, sim=0.9569\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9232\n",
      "[swap_spelling_aug] attempt 1, sim=0.9282\n",
      "[delete_aug] attempt 2, sim=0.9894\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9271\n",
      "[swap_spelling_aug] attempt 2, sim=0.9285\n",
      "[delete_aug] attempt 4, sim=0.9780\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9573\n",
      "[swap_spelling_aug] attempt 1, sim=0.9353\n",
      "[delete_aug] attempt 1, sim=0.9557\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9728\n",
      "[swap_spelling_aug] attempt 1, sim=0.9337\n",
      "[delete_aug] attempt 1, sim=0.9427\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9520\n",
      "[swap_spelling_aug] attempt 1, sim=0.9662\n",
      "[delete_aug] attempt 1, sim=0.9729\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9452\n",
      "[swap_spelling_aug] attempt 1, sim=0.9469\n",
      "[delete_aug] attempt 1, sim=0.9630\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9240\n",
      "[swap_spelling_aug] attempt 1, sim=0.9440\n",
      "[delete_aug] attempt 1, sim=0.9732\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9647\n",
      "[swap_spelling_aug] attempt 2, sim=0.9273\n",
      "[delete_aug] attempt 1, sim=0.9852\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9427\n",
      "[swap_spelling_aug] attempt 1, sim=0.9334\n",
      "[delete_aug] attempt 1, sim=0.9241\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9360\n",
      "[swap_spelling_aug] attempt 1, sim=0.9809\n",
      "[delete_aug] attempt 1, sim=0.9844\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9582\n",
      "[swap_spelling_aug] attempt 1, sim=0.9158\n",
      "[delete_aug] attempt 1, sim=0.9755\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9738\n",
      "[swap_spelling_aug] attempt 1, sim=0.9636\n",
      "[delete_aug] attempt 1, sim=0.9649\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9882\n",
      "[swap_spelling_aug] attempt 1, sim=0.9533\n",
      "[delete_aug] attempt 1, sim=0.9632\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9283\n",
      "[swap_spelling_aug] attempt 1, sim=0.9625\n",
      "[delete_aug] attempt 2, sim=0.9427\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9401\n",
      "[swap_spelling_aug] attempt 1, sim=0.9172\n",
      "[delete_aug] attempt 1, sim=0.9596\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9245\n",
      "[swap_spelling_aug] attempt 1, sim=0.9052\n",
      "[delete_aug] attempt 1, sim=0.9892\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9111\n",
      "[swap_spelling_aug] attempt 1, sim=0.9224\n",
      "[delete_aug] attempt 1, sim=0.9831\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9660\n",
      "[swap_spelling_aug] attempt 1, sim=0.9573\n",
      "[delete_aug] attempt 2, sim=0.9893\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9804\n",
      "[swap_spelling_aug] attempt 1, sim=0.9677\n",
      "[delete_aug] attempt 1, sim=0.9767\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9430\n",
      "[swap_spelling_aug] attempt 2, sim=0.9610\n",
      "[delete_aug] attempt 1, sim=0.9693\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9341\n",
      "[swap_spelling_aug] attempt 1, sim=0.9199\n",
      "[delete_aug] attempt 1, sim=0.9398\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9787\n",
      "[swap_spelling_aug] attempt 2, sim=0.9687\n",
      "[delete_aug] attempt 1, sim=0.9854\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9591\n",
      "[swap_spelling_aug] attempt 1, sim=0.9823\n",
      "[delete_aug] attempt 1, sim=0.9874\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9841\n",
      "[swap_spelling_aug] attempt 2, sim=0.9670\n",
      "[delete_aug] attempt 1, sim=0.9602\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9166\n",
      "[swap_spelling_aug] attempt 1, sim=0.9767\n",
      "[delete_aug] attempt 3, sim=0.9682\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9799\n",
      "[swap_spelling_aug] attempt 1, sim=0.9662\n",
      "[delete_aug] attempt 1, sim=0.9746\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9559\n",
      "[swap_spelling_aug] attempt 1, sim=0.9073\n",
      "[delete_aug] attempt 1, sim=0.9891\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9635\n",
      "[swap_spelling_aug] attempt 1, sim=0.9300\n",
      "[delete_aug] attempt 1, sim=0.9265\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9129\n",
      "[swap_spelling_aug] attempt 1, sim=0.9710\n",
      "[delete_aug] attempt 1, sim=0.9233\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9418\n",
      "[swap_spelling_aug] attempt 1, sim=0.9552\n",
      "[delete_aug] attempt 1, sim=0.9425\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9164\n",
      "[swap_spelling_aug] attempt 1, sim=0.9653\n",
      "[delete_aug] attempt 1, sim=0.9592\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9134\n",
      "[swap_spelling_aug] attempt 2, sim=0.9701\n",
      "[delete_aug] attempt 3, sim=0.9788\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9733\n",
      "[swap_spelling_aug] attempt 1, sim=0.9710\n",
      "[delete_aug] attempt 1, sim=0.9821\n",
      "[swap_sym_word_aug] attempt 4, sim=0.9738\n",
      "[swap_spelling_aug] attempt 1, sim=0.9506\n",
      "[delete_aug] attempt 1, sim=0.9871\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9071\n",
      "[swap_spelling_aug] attempt 1, sim=0.9750\n",
      "[delete_aug] attempt 1, sim=0.9845\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9593\n",
      "[swap_spelling_aug] attempt 1, sim=0.9545\n",
      "[delete_aug] attempt 1, sim=0.9853\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9181\n",
      "[swap_spelling_aug] attempt 2, sim=0.9756\n",
      "[delete_aug] attempt 4, sim=0.9808\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9869\n",
      "[swap_spelling_aug] attempt 2, sim=0.9827\n",
      "[delete_aug] attempt 1, sim=0.9878\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9391\n",
      "[swap_spelling_aug] attempt 1, sim=0.9597\n",
      "[delete_aug] attempt 1, sim=0.9798\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9502\n",
      "[swap_spelling_aug] attempt 2, sim=0.9810\n",
      "[delete_aug] attempt 1, sim=0.9186\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9437\n",
      "[swap_spelling_aug] attempt 2, sim=0.9637\n",
      "[delete_aug] attempt 1, sim=0.9660\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9661\n",
      "[swap_spelling_aug] attempt 1, sim=0.9322\n",
      "[delete_aug] attempt 1, sim=0.9257\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9435\n",
      "[swap_spelling_aug] attempt 2, sim=0.9137\n",
      "[delete_aug] attempt 3, sim=0.9890\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9240\n",
      "[swap_spelling_aug] attempt 1, sim=0.9339\n",
      "[delete_aug] attempt 1, sim=0.9611\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9872\n",
      "[swap_spelling_aug] attempt 1, sim=0.9783\n",
      "[delete_aug] attempt 3, sim=0.9470\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9812\n",
      "[swap_spelling_aug] attempt 1, sim=0.9391\n",
      "[delete_aug] attempt 1, sim=0.9784\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9107\n",
      "[swap_spelling_aug] attempt 1, sim=0.9690\n",
      "[delete_aug] attempt 1, sim=0.9607\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9786\n",
      "[swap_spelling_aug] attempt 1, sim=0.9377\n",
      "[delete_aug] attempt 1, sim=0.9591\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9355\n",
      "[swap_spelling_aug] attempt 1, sim=0.9897\n",
      "[delete_aug] attempt 1, sim=0.9896\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9841\n",
      "[swap_spelling_aug] attempt 1, sim=0.9445\n",
      "[delete_aug] attempt 1, sim=0.9502\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9086\n",
      "[swap_spelling_aug] attempt 2, sim=0.9823\n",
      "[delete_aug] attempt 1, sim=0.9658\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9010\n",
      "[swap_spelling_aug] attempt 1, sim=0.9500\n",
      "[delete_aug] attempt 1, sim=0.9772\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9398\n",
      "[swap_spelling_aug] attempt 2, sim=0.9408\n",
      "[delete_aug] attempt 1, sim=0.9207\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9175\n",
      "[swap_spelling_aug] attempt 2, sim=0.9873\n",
      "[delete_aug] attempt 1, sim=0.9611\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9029\n",
      "[swap_spelling_aug] attempt 1, sim=0.9752\n",
      "[delete_aug] attempt 3, sim=0.9726\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9140\n",
      "[swap_spelling_aug] attempt 1, sim=0.9521\n",
      "[delete_aug] attempt 1, sim=0.9316\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9219\n",
      "[swap_spelling_aug] attempt 1, sim=0.9751\n",
      "[delete_aug] attempt 1, sim=0.9846\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9520\n",
      "[swap_spelling_aug] attempt 1, sim=0.9442\n",
      "[delete_aug] attempt 1, sim=0.9665\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9371\n",
      "[swap_spelling_aug] attempt 3, sim=0.9853\n",
      "[delete_aug] attempt 1, sim=0.9858\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9748\n",
      "[swap_spelling_aug] attempt 1, sim=0.9791\n",
      "[delete_aug] attempt 1, sim=0.9885\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9660\n",
      "[swap_spelling_aug] attempt 1, sim=0.9596\n",
      "[delete_aug] attempt 1, sim=0.9795\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9152\n",
      "[swap_spelling_aug] attempt 1, sim=0.9466\n",
      "[delete_aug] attempt 1, sim=0.9639\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9647\n",
      "[swap_spelling_aug] attempt 1, sim=0.9068\n",
      "[delete_aug] attempt 1, sim=0.9866\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9810\n",
      "[swap_spelling_aug] attempt 1, sim=0.9788\n",
      "[delete_aug] attempt 3, sim=0.9659\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9728\n",
      "[swap_spelling_aug] attempt 2, sim=0.9809\n",
      "[delete_aug] attempt 1, sim=0.9675\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9023\n",
      "[swap_spelling_aug] attempt 1, sim=0.9583\n",
      "[delete_aug] attempt 1, sim=0.9697\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9318\n",
      "[swap_spelling_aug] attempt 1, sim=0.9393\n",
      "[delete_aug] attempt 1, sim=0.9743\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9276\n",
      "[swap_spelling_aug] attempt 1, sim=0.9662\n",
      "[delete_aug] attempt 1, sim=0.9742\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9702\n",
      "[swap_spelling_aug] attempt 1, sim=0.9532\n",
      "[delete_aug] attempt 1, sim=0.9785\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9632\n",
      "[swap_spelling_aug] attempt 2, sim=0.9840\n",
      "[delete_aug] attempt 4, sim=0.9374\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9815\n",
      "[swap_spelling_aug] attempt 1, sim=0.9819\n",
      "[delete_aug] attempt 1, sim=0.9699\n",
      "[swap_sym_word_aug] attempt 4, sim=0.9820\n",
      "[swap_spelling_aug] attempt 1, sim=0.9159\n",
      "[delete_aug] attempt 1, sim=0.9759\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9497\n",
      "[swap_spelling_aug] attempt 1, sim=0.9208\n",
      "[delete_aug] attempt 1, sim=0.9516\n",
      "[swap_sym_word_aug] attempt 6, sim=0.9490\n",
      "[swap_spelling_aug] attempt 7, sim=0.9322\n",
      "[delete_aug] attempt 1, sim=0.9736\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9278\n",
      "[swap_spelling_aug] attempt 1, sim=0.9769\n",
      "[delete_aug] attempt 3, sim=0.9762\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9048\n",
      "[swap_spelling_aug] attempt 1, sim=0.9659\n",
      "[delete_aug] attempt 2, sim=0.9725\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9860\n",
      "[swap_spelling_aug] attempt 2, sim=0.9305\n",
      "[delete_aug] attempt 1, sim=0.9630\n",
      "[swap_sym_word_aug] attempt 3, sim=0.9249\n",
      "[swap_spelling_aug] attempt 1, sim=0.9653\n",
      "[delete_aug] attempt 1, sim=0.9556\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9241\n",
      "[swap_spelling_aug] attempt 1, sim=0.9103\n",
      "[delete_aug] attempt 2, sim=0.9818\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9857\n",
      "[swap_spelling_aug] attempt 3, sim=0.9618\n",
      "[delete_aug] attempt 2, sim=0.9643\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9716\n",
      "[swap_spelling_aug] attempt 1, sim=0.9636\n",
      "[delete_aug] attempt 1, sim=0.9648\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9452\n",
      "[swap_spelling_aug] attempt 1, sim=0.9450\n",
      "[delete_aug] attempt 2, sim=0.9664\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9741\n",
      "[swap_spelling_aug] attempt 1, sim=0.9680\n",
      "[delete_aug] attempt 4, sim=0.9797\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9834\n",
      "[swap_spelling_aug] attempt 1, sim=0.9329\n",
      "[delete_aug] attempt 2, sim=0.9701\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9215\n",
      "[swap_spelling_aug] attempt 1, sim=0.9096\n",
      "[delete_aug] attempt 3, sim=0.9855\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9405\n",
      "[swap_spelling_aug] attempt 2, sim=0.9425\n",
      "[delete_aug] attempt 1, sim=0.9684\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9695\n",
      "[swap_spelling_aug] attempt 1, sim=0.9218\n",
      "[delete_aug] attempt 1, sim=0.9360\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9483\n",
      "[swap_spelling_aug] attempt 1, sim=0.9469\n",
      "[delete_aug] attempt 1, sim=0.9576\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9536\n",
      "[swap_spelling_aug] attempt 1, sim=0.9331\n",
      "[delete_aug] attempt 1, sim=0.9749\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9863\n",
      "[swap_spelling_aug] attempt 1, sim=0.9517\n",
      "[delete_aug] attempt 2, sim=0.9696\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9554\n",
      "[swap_spelling_aug] attempt 2, sim=0.9785\n",
      "[delete_aug] attempt 2, sim=0.9754\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9900\n",
      "[swap_spelling_aug] attempt 1, sim=0.9812\n",
      "[delete_aug] attempt 2, sim=0.9865\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9842\n",
      "[swap_spelling_aug] attempt 1, sim=0.9508\n",
      "[delete_aug] attempt 2, sim=0.9886\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9155\n",
      "[swap_spelling_aug] attempt 1, sim=0.9177\n",
      "[delete_aug] attempt 1, sim=0.9822\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9630\n",
      "[swap_spelling_aug] attempt 1, sim=0.9635\n",
      "[delete_aug] attempt 2, sim=0.9649\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9718\n",
      "[swap_spelling_aug] attempt 1, sim=0.9759\n",
      "[delete_aug] attempt 1, sim=0.9819\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9629\n",
      "[swap_spelling_aug] attempt 1, sim=0.9324\n",
      "[delete_aug] attempt 1, sim=0.9481\n",
      "[swap_sym_word_aug] attempt 2, sim=0.9326\n",
      "[swap_spelling_aug] attempt 1, sim=0.9700\n",
      "[delete_aug] attempt 1, sim=0.9822\n",
      "[swap_sym_word_aug] attempt 1, sim=0.9766\n",
      "[swap_spelling_aug] attempt 1, sim=0.9763\n",
      "[delete_aug] attempt 1, sim=0.9852\n"
     ]
    }
   ],
   "source": [
    "text_augmentation(src_bucket = \"training-data-construction-zone\", dest_bucket = \"training-data-construction-zone\", model_text = model, tokenizer=tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
